{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/proj/venv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "from datasets import load_dataset\n",
    "from transformers import (\n",
    "    AutoModelForCausalLM,\n",
    "    AutoTokenizer,\n",
    "    BitsAndBytesConfig,\n",
    "    TrainingArguments,\n",
    "    pipeline,\n",
    "    logging,\n",
    ")\n",
    "from peft import LoraConfig, PeftModel\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_model = \"./model/new_model/\"\n",
    "base_model = \"./model/base_model/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_dtype = getattr(torch, \"float16\")\n",
    "\n",
    "quant_config = BitsAndBytesConfig(\n",
    "    load_in_8bit=True,\n",
    "    bnb_8bit_quant_type=\"nf4\",\n",
    "    bnb_8bit_compute_dtype=compute_dtype,\n",
    "    bnb_8bit_use_double_quant=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 2/2 [01:42<00:00, 51.39s/it]\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    base_model,\n",
    "    quantization_config=quant_config,\n",
    "    device_map={\"\": 0}\n",
    ")\n",
    "model.config.use_cache = False\n",
    "model.config.pretraining_tp = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Cannot merge LORA layers when the model is loaded in 8-bit mode",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/home/ubuntu/proj/Load_using_model.ipynb Cell 5\u001b[0m line \u001b[0;36m2\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Btest/home/ubuntu/proj/Load_using_model.ipynb#W4sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m bg_model \u001b[39m=\u001b[39m PeftModel\u001b[39m.\u001b[39mfrom_pretrained(model, new_model)\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2Btest/home/ubuntu/proj/Load_using_model.ipynb#W4sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m bg_model \u001b[39m=\u001b[39m bg_model\u001b[39m.\u001b[39;49mmerge_and_unload()\n",
      "File \u001b[0;32m~/proj/venv/lib/python3.10/site-packages/peft/tuners/lora.py:618\u001b[0m, in \u001b[0;36mLoraModel.merge_and_unload\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    601\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mmerge_and_unload\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    602\u001b[0m \u001b[39m    \u001b[39m\u001b[39mr\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    603\u001b[0m \u001b[39m    This method merges the LoRa layers into the base model. This is needed if someone wants to use the base model\u001b[39;00m\n\u001b[1;32m    604\u001b[0m \u001b[39m    as a standalone model.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    616\u001b[0m \u001b[39m    ```\u001b[39;00m\n\u001b[1;32m    617\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 618\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_unload_and_optionally_merge()\n",
      "File \u001b[0;32m~/proj/venv/lib/python3.10/site-packages/peft/tuners/lora.py:440\u001b[0m, in \u001b[0;36mLoraModel._unload_and_optionally_merge\u001b[0;34m(self, merge)\u001b[0m\n\u001b[1;32m    438\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_unload_and_optionally_merge\u001b[39m(\u001b[39mself\u001b[39m, merge\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m):\n\u001b[1;32m    439\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mgetattr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel, \u001b[39m\"\u001b[39m\u001b[39mis_loaded_in_8bit\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mFalse\u001b[39;00m) \u001b[39mor\u001b[39;00m \u001b[39mgetattr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel, \u001b[39m\"\u001b[39m\u001b[39mis_loaded_in_4bit\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mFalse\u001b[39;00m):\n\u001b[0;32m--> 440\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mCannot merge LORA layers when the model is loaded in 8-bit mode\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    442\u001b[0m     key_list \u001b[39m=\u001b[39m [key \u001b[39mfor\u001b[39;00m key, _ \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel\u001b[39m.\u001b[39mnamed_modules() \u001b[39mif\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mlora\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m key]\n\u001b[1;32m    443\u001b[0m     \u001b[39mfor\u001b[39;00m key \u001b[39min\u001b[39;00m key_list:\n",
      "\u001b[0;31mValueError\u001b[0m: Cannot merge LORA layers when the model is loaded in 8-bit mode"
     ]
    }
   ],
   "source": [
    "#bg_model = PeftModel.from_pretrained(model, new_model)\n",
    "#bg_model = bg_model.merge_and_unload()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(new_model)\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "tokenizer.padding_side = \"right\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Xformers is not installed correctly. If you want to use memory_efficient_attention to accelerate training use the following command to install Xformers\n",
      "pip install xformers.\n"
     ]
    }
   ],
   "source": [
    "pipe = pipeline(task=\"text-generation\", model=model, tokenizer=tokenizer, max_length=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate(text, pipeline=pipe):\n",
    "  # Ignore warnings\n",
    "\n",
    "  start_time = time.time()\n",
    "  logging.set_verbosity(logging.CRITICAL)\n",
    "\n",
    "  # Run text generation pipeline with our next model\n",
    "  prompt = text\n",
    "  result = pipeline(f\"[INST] {prompt} [/INST]\")\n",
    "  end_time = time.time()\n",
    "  execution_time = end_time - start_time\n",
    "  print(\"Execution time:\",execution_time)\n",
    "  print(result[0]['generated_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Execution time: 33.94137620925903\n",
      "[INST] Какво да си сготвя днес? Имам картофи, месо. подправки. [/INST] Начин на приготвяне на Картофи с месо: Картофите се сваряват и се нарязват на филийки. Месото се сварява и се нарязва на малки парчета. В тава се нареждат картофите, отгоре се слага месото и се поръсва с подправките. Залива се с вода и се пече до готовност. 10 минути преди да се извади от фурната се поръсва с магданоз. 10 минути след като се извади от фурната се поръсва с чесън. 10 минути\n"
     ]
    }
   ],
   "source": [
    "generate(\"Какво да си сготвя днес? Имам картофи, месо. подправки.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Execution time: 34.296059370040894\n",
      "[INST] Знаеш ли как мога да тренирам невронна мрежа? [/INST]  Който е в състояние да се простира в тази течност, може да се тренират невронни мрежи с помощта на следните подходи: 1.1. Мозък: 1.1.1. Мозъкът е най-добрият подход за трениране на невронни мрежи. 1.1.2. Мозъкът е най-добрият подход за трениране на невронни мрежи. 1.2. Компютер: 1.2.1. Компютерът е най-добрият подход за трениране на невронни мрежи. 1.\n"
     ]
    }
   ],
   "source": [
    "generate(\"Знаеш ли как мога да тренирам невронна мрежа?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
