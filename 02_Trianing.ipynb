{"cells":[{"cell_type":"markdown","metadata":{},"source":["# Trianing and saving the model"]},{"cell_type":"code","execution_count":13,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":540,"status":"ok","timestamp":1700922776273,"user":{"displayName":"Teodor Chakarov","userId":"05481855163891350543"},"user_tz":-60},"id":"5hQE5O7DU6lM","outputId":"0849394e-f0a1-49f6-d60f-3fcb926b9dff"},"outputs":[{"name":"stdout","output_type":"stream","text":["Tue Nov 28 19:03:19 2023       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 510.47.03    Driver Version: 510.47.03    CUDA Version: 11.6     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  NVIDIA A10G         On   | 00000000:00:1E.0 Off |                    0 |\n","|  0%   31C    P0    57W / 300W |   4975MiB / 23028MiB |      3%      Default |\n","|                               |                      |                  N/A |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","|    0   N/A  N/A     10050      C   ...untu/proj/venv/bin/python     4973MiB |\n","+-----------------------------------------------------------------------------+\n"]}],"source":["!nvidia-smi"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3,"status":"ok","timestamp":1700922776273,"user":{"displayName":"Teodor Chakarov","userId":"05481855163891350543"},"user_tz":-60},"id":"DNJ5dyeGx2xm","outputId":"61be5519-4abd-4e05-ed3c-37e4f56265a2"},"outputs":[{"name":"stdout","output_type":"stream","text":["Python 3.10.1\n"]}],"source":["!python --version"]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["nvcc: NVIDIA (R) Cuda compiler driver\n","Copyright (c) 2005-2021 NVIDIA Corporation\n","Built on Mon_May__3_19:15:13_PDT_2021\n","Cuda compilation tools, release 11.3, V11.3.109\n","Build cuda_11.3.r11.3/compiler.29920130_0\n"]}],"source":["!nvcc --version"]},{"cell_type":"markdown","metadata":{},"source":["## Issues with the project I saw"]},{"cell_type":"markdown","metadata":{},"source":["Since I don't have such a powerful GPU on my private laptop I am using AWS infrastructure in that case. One of the problems is that the AWS EC2 instance is using old AMI images (pre-defined Linux snapshots with installed libraries). In this case, using the old version of CUDA. That's why I needed to install the respective versions of Pytorch and transformers. \n","The next command is to uninstall one problematic nvidia_cublas_cu11 driver."]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[],"source":["#!yes | pip uninstall nvidia_cublas_cu11"]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":22658,"status":"ok","timestamp":1700922798930,"user":{"displayName":"Teodor Chakarov","userId":"05481855163891350543"},"user_tz":-60},"id":"IJfm3GVtVH-0","outputId":"744cc9b6-427a-4dc7-d000-652c02b6236c"},"outputs":[{"name":"stderr","output_type":"stream","text":["/home/ubuntu/proj/venv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n","  from .autonotebook import tqdm as notebook_tqdm\n"]}],"source":["import os\n","import torch\n","from datasets import load_dataset\n","from transformers import (\n","    AutoModelForCausalLM,\n","    AutoTokenizer,\n","    BitsAndBytesConfig,\n","    TrainingArguments,\n","    pipeline,\n","    logging,\n",")\n","from peft import LoraConfig\n","from trl import SFTTrainer\n","import time"]},{"cell_type":"code","execution_count":6,"metadata":{"executionInfo":{"elapsed":12,"status":"ok","timestamp":1700922798931,"user":{"displayName":"Teodor Chakarov","userId":"05481855163891350543"},"user_tz":-60},"id":"_4wMVyvLV7yq"},"outputs":[],"source":["hf_link = \"NousResearch/Llama-2-7b-chat-hf\"\n","data = \"./data/train_data.csv\"\n","new_model = \"./model/new_model/\"\n","base_model = \"./model/base_model/\""]},{"cell_type":"code","execution_count":7,"metadata":{"executionInfo":{"elapsed":1235,"status":"ok","timestamp":1700922800155,"user":{"displayName":"Teodor Chakarov","userId":"05481855163891350543"},"user_tz":-60},"id":"C1IK7zbXV7vj"},"outputs":[],"source":["train_data = load_dataset(\"csv\", data_files=data)\n","train_data = train_data.rename_column(\"promped_text\", \"text\")"]},{"cell_type":"code","execution_count":8,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4,"status":"ok","timestamp":1700922800155,"user":{"displayName":"Teodor Chakarov","userId":"05481855163891350543"},"user_tz":-60},"id":"pPzQJBtFzEEW","outputId":"e58a001b-78f4-42a7-da67-6193e36d975b"},"outputs":[{"data":{"text/plain":["DatasetDict({\n","    train: Dataset({\n","        features: ['text'],\n","        num_rows: 63260\n","    })\n","})"]},"execution_count":8,"metadata":{},"output_type":"execute_result"}],"source":["train_data"]},{"cell_type":"code","execution_count":9,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":598,"status":"ok","timestamp":1700922800751,"user":{"displayName":"Teodor Chakarov","userId":"05481855163891350543"},"user_tz":-60},"id":"ZBBiRR7CV7sj","outputId":"97c0d991-097a-4fbd-d4ff-16cb2241d5ff"},"outputs":[{"data":{"text/plain":["{'text': '<s>[INST] Искам да сготвя нещо хубаво. Имам налични следните продукти: пудра захар, желатин ( пакетче), маргарин, глюкоза, ванилия [/INST] Може да приготвиш Фондан за покритие на торти - II вид: Захарта се пресява и се изсипва в дълбок съд. В средата се прави кладенче. Желатина се накисва в 3 ч.л. хладка вода за 5 минути, след това се разтопява на водна баня. Добавят се маргарина и глюкозата и всичко се изсипва в кладенчето, заедно с ванилията. След това се омесва добре, докато тестото се получи горе-долу като пластелин. Неизползваното количество се прибира в пликче в хладилник.'}"]},"execution_count":9,"metadata":{},"output_type":"execute_result"}],"source":["train_data[\"train\"][0]"]},{"cell_type":"code","execution_count":10,"metadata":{"executionInfo":{"elapsed":3,"status":"ok","timestamp":1700922800751,"user":{"displayName":"Teodor Chakarov","userId":"05481855163891350543"},"user_tz":-60},"id":"fKE2Ex8MV7pj"},"outputs":[],"source":["compute_dtype = getattr(torch, \"float16\")\n","\n","quant_config = BitsAndBytesConfig(\n","    load_in_4bit=True,\n","    bnb_4bit_quant_type=\"nf4\",\n","    bnb_4bit_compute_dtype=compute_dtype,\n","    bnb_4bit_use_double_quant=False,\n",")"]},{"cell_type":"code","execution_count":11,"metadata":{"executionInfo":{"elapsed":2,"status":"ok","timestamp":1700922800751,"user":{"displayName":"Teodor Chakarov","userId":"05481855163891350543"},"user_tz":-60},"id":"jIpBw-FA0wb1"},"outputs":[{"name":"stdout","output_type":"stream","text":["================================================================================\n","Your GPU supports bfloat16: accelerate training with bf16=True\n","================================================================================\n"]}],"source":["# Check GPU compatibility with bfloat16\n","if compute_dtype == torch.float16:\n","    major, _ = torch.cuda.get_device_capability()\n","    if major >= 8:\n","        print(\"=\" * 80)\n","        print(\"Your GPU supports bfloat16: accelerate training with bf16=True\")\n","        print(\"=\" * 80)"]},{"cell_type":"code","execution_count":12,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":138,"referenced_widgets":["70705121ed974717aed4c0d99899d686","a30cd9e78033470c89174fa061f2806e","e59a90f0aa2448adb36d7fad874c1657","4ed43cefc0824e869fea609b5520a6c1","4e3b5c24873846bda821176a1fbacbc3","cff3274e8c6e457db45782700785ce68","0dfb723963094c3d8994a3edd0716cc1","2f594f7c38b8400c883556d27991d4f3","d6bfb3b1a0db408ebfbaa701312409b6","11f1fb24098f40bc944eebc578d47839","2fcb1360c00c4754aef83ebef6ad3128"]},"executionInfo":{"elapsed":66128,"status":"ok","timestamp":1700922866877,"user":{"displayName":"Teodor Chakarov","userId":"05481855163891350543"},"user_tz":-60},"id":"bs4UPCMjVH7O","outputId":"df3be90b-3cd6-4050-a71c-b8fe7dcd0634"},"outputs":[{"name":"stderr","output_type":"stream","text":["config.json: 100%|██████████| 583/583 [00:00<00:00, 3.72MB/s]\n","model.safetensors.index.json: 100%|██████████| 26.8k/26.8k [00:00<00:00, 60.1MB/s]\n","model-00001-of-00002.safetensors: 100%|██████████| 9.98G/9.98G [01:01<00:00, 162MB/s]\n","model-00002-of-00002.safetensors: 100%|██████████| 3.50G/3.50G [00:26<00:00, 131MB/s]\n","Downloading shards: 100%|██████████| 2/2 [01:28<00:00, 44.27s/it]\n","Loading checkpoint shards: 100%|██████████| 2/2 [02:02<00:00, 61.28s/it]\n","generation_config.json: 100%|██████████| 179/179 [00:00<00:00, 869kB/s]\n"]}],"source":["model = AutoModelForCausalLM.from_pretrained(\n","    hf_link,\n","    quantization_config=quant_config,\n","    device_map={\"\": 0}\n",")\n","model.config.use_cache = False\n","model.config.pretraining_tp = 1"]},{"cell_type":"code","execution_count":14,"metadata":{"executionInfo":{"elapsed":572,"status":"ok","timestamp":1700922867438,"user":{"displayName":"Teodor Chakarov","userId":"05481855163891350543"},"user_tz":-60},"id":"_olCkcA-VH4F"},"outputs":[{"name":"stderr","output_type":"stream","text":["tokenizer_config.json: 100%|██████████| 746/746 [00:00<00:00, 3.53MB/s]\n","tokenizer.model: 100%|██████████| 500k/500k [00:00<00:00, 415MB/s]\n","tokenizer.json: 100%|██████████| 1.84M/1.84M [00:00<00:00, 5.06MB/s]\n","added_tokens.json: 100%|██████████| 21.0/21.0 [00:00<00:00, 106kB/s]\n","special_tokens_map.json: 100%|██████████| 435/435 [00:00<00:00, 3.06MB/s]\n"]}],"source":["tokenizer = AutoTokenizer.from_pretrained(hf_link)\n","tokenizer.pad_token = tokenizer.eos_token\n","tokenizer.padding_side = \"right\""]},{"cell_type":"code","execution_count":15,"metadata":{},"outputs":[],"source":["#!sudo cp -L -R ~/.cache/huggingface/hub/models--NousResearch--Llama-2-7b-chat-hf/snapshots/37892f30c23786c0d5367d80481fa0d9fba93cf8/* ./model/base_model"]},{"cell_type":"code","execution_count":16,"metadata":{"executionInfo":{"elapsed":3,"status":"ok","timestamp":1700922867439,"user":{"displayName":"Teodor Chakarov","userId":"05481855163891350543"},"user_tz":-60},"id":"fFHbGH5rVHyZ"},"outputs":[],"source":["peft_params = LoraConfig(\n","    lora_alpha=16,\n","    lora_dropout=0.1,\n","    r=64,\n","    bias=\"none\",\n","    task_type=\"CAUSAL_LM\",\n",")"]},{"cell_type":"code","execution_count":23,"metadata":{"executionInfo":{"elapsed":2,"status":"ok","timestamp":1700922867439,"user":{"displayName":"Teodor Chakarov","userId":"05481855163891350543"},"user_tz":-60},"id":"5p05NCktVHve"},"outputs":[],"source":["training_params = TrainingArguments(\n","    output_dir=\"./results\",\n","    num_train_epochs=1,\n","    per_device_train_batch_size=5,\n","    gradient_accumulation_steps=1,\n","    optim=\"paged_adamw_32bit\",\n","    save_steps=2000,\n","    logging_steps=100,\n","    learning_rate=2e-4,\n","    weight_decay=0.001,\n","    max_grad_norm=0.3,\n","    max_steps=-1,\n","    warmup_ratio=0.03,\n","    group_by_length=True,\n","    lr_scheduler_type=\"constant\"\n",")"]},{"cell_type":"code","execution_count":24,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":575,"status":"ok","timestamp":1700922868012,"user":{"displayName":"Teodor Chakarov","userId":"05481855163891350543"},"user_tz":-60},"id":"niy5ak7nymuq","outputId":"1539e49f-01c0-4f83-d28a-bed68d94a8b8"},"outputs":[{"name":"stderr","output_type":"stream","text":["Map: 100%|██████████| 63260/63260 [00:13<00:00, 4674.02 examples/s]\n"]}],"source":["trainer = SFTTrainer(\n","    model=model,\n","    train_dataset=train_data[\"train\"],\n","    peft_config=peft_params,\n","    dataset_text_field=\"text\",\n","    max_seq_length=None,\n","    tokenizer=tokenizer,\n","    args=training_params\n",")"]},{"cell_type":"code","execution_count":25,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":427},"executionInfo":{"elapsed":32165,"status":"error","timestamp":1700922904165,"user":{"displayName":"Teodor Chakarov","userId":"05481855163891350543"},"user_tz":-60},"id":"nsg4OWTr3rVt","outputId":"938b08bc-6955-4dca-e7f1-f6fb54beec3c"},"outputs":[{"data":{"text/html":["\n","    <div>\n","      \n","      <progress value='12652' max='12652' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [12652/12652 6:37:36, Epoch 1/1]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>100</td>\n","      <td>1.796900</td>\n","    </tr>\n","    <tr>\n","      <td>200</td>\n","      <td>1.393600</td>\n","    </tr>\n","    <tr>\n","      <td>300</td>\n","      <td>1.327900</td>\n","    </tr>\n","    <tr>\n","      <td>400</td>\n","      <td>1.249500</td>\n","    </tr>\n","    <tr>\n","      <td>500</td>\n","      <td>1.230700</td>\n","    </tr>\n","    <tr>\n","      <td>600</td>\n","      <td>1.196400</td>\n","    </tr>\n","    <tr>\n","      <td>700</td>\n","      <td>1.180500</td>\n","    </tr>\n","    <tr>\n","      <td>800</td>\n","      <td>1.151000</td>\n","    </tr>\n","    <tr>\n","      <td>900</td>\n","      <td>1.142300</td>\n","    </tr>\n","    <tr>\n","      <td>1000</td>\n","      <td>1.136300</td>\n","    </tr>\n","    <tr>\n","      <td>1100</td>\n","      <td>1.139200</td>\n","    </tr>\n","    <tr>\n","      <td>1200</td>\n","      <td>1.101600</td>\n","    </tr>\n","    <tr>\n","      <td>1300</td>\n","      <td>1.108800</td>\n","    </tr>\n","    <tr>\n","      <td>1400</td>\n","      <td>1.092300</td>\n","    </tr>\n","    <tr>\n","      <td>1500</td>\n","      <td>1.080400</td>\n","    </tr>\n","    <tr>\n","      <td>1600</td>\n","      <td>1.079200</td>\n","    </tr>\n","    <tr>\n","      <td>1700</td>\n","      <td>1.052800</td>\n","    </tr>\n","    <tr>\n","      <td>1800</td>\n","      <td>1.047800</td>\n","    </tr>\n","    <tr>\n","      <td>1900</td>\n","      <td>1.047400</td>\n","    </tr>\n","    <tr>\n","      <td>2000</td>\n","      <td>1.042900</td>\n","    </tr>\n","    <tr>\n","      <td>2100</td>\n","      <td>1.047100</td>\n","    </tr>\n","    <tr>\n","      <td>2200</td>\n","      <td>1.025000</td>\n","    </tr>\n","    <tr>\n","      <td>2300</td>\n","      <td>1.038000</td>\n","    </tr>\n","    <tr>\n","      <td>2400</td>\n","      <td>1.028100</td>\n","    </tr>\n","    <tr>\n","      <td>2500</td>\n","      <td>1.019000</td>\n","    </tr>\n","    <tr>\n","      <td>2600</td>\n","      <td>1.019500</td>\n","    </tr>\n","    <tr>\n","      <td>2700</td>\n","      <td>1.002900</td>\n","    </tr>\n","    <tr>\n","      <td>2800</td>\n","      <td>1.004400</td>\n","    </tr>\n","    <tr>\n","      <td>2900</td>\n","      <td>0.992000</td>\n","    </tr>\n","    <tr>\n","      <td>3000</td>\n","      <td>0.996700</td>\n","    </tr>\n","    <tr>\n","      <td>3100</td>\n","      <td>0.983900</td>\n","    </tr>\n","    <tr>\n","      <td>3200</td>\n","      <td>0.991500</td>\n","    </tr>\n","    <tr>\n","      <td>3300</td>\n","      <td>0.964600</td>\n","    </tr>\n","    <tr>\n","      <td>3400</td>\n","      <td>0.974700</td>\n","    </tr>\n","    <tr>\n","      <td>3500</td>\n","      <td>0.985800</td>\n","    </tr>\n","    <tr>\n","      <td>3600</td>\n","      <td>0.962200</td>\n","    </tr>\n","    <tr>\n","      <td>3700</td>\n","      <td>0.971100</td>\n","    </tr>\n","    <tr>\n","      <td>3800</td>\n","      <td>0.956900</td>\n","    </tr>\n","    <tr>\n","      <td>3900</td>\n","      <td>0.954800</td>\n","    </tr>\n","    <tr>\n","      <td>4000</td>\n","      <td>0.961100</td>\n","    </tr>\n","    <tr>\n","      <td>4100</td>\n","      <td>0.951900</td>\n","    </tr>\n","    <tr>\n","      <td>4200</td>\n","      <td>0.955600</td>\n","    </tr>\n","    <tr>\n","      <td>4300</td>\n","      <td>0.943200</td>\n","    </tr>\n","    <tr>\n","      <td>4400</td>\n","      <td>0.931900</td>\n","    </tr>\n","    <tr>\n","      <td>4500</td>\n","      <td>0.955800</td>\n","    </tr>\n","    <tr>\n","      <td>4600</td>\n","      <td>0.940500</td>\n","    </tr>\n","    <tr>\n","      <td>4700</td>\n","      <td>0.961500</td>\n","    </tr>\n","    <tr>\n","      <td>4800</td>\n","      <td>0.931500</td>\n","    </tr>\n","    <tr>\n","      <td>4900</td>\n","      <td>0.929700</td>\n","    </tr>\n","    <tr>\n","      <td>5000</td>\n","      <td>0.925100</td>\n","    </tr>\n","    <tr>\n","      <td>5100</td>\n","      <td>0.922200</td>\n","    </tr>\n","    <tr>\n","      <td>5200</td>\n","      <td>0.930000</td>\n","    </tr>\n","    <tr>\n","      <td>5300</td>\n","      <td>0.932000</td>\n","    </tr>\n","    <tr>\n","      <td>5400</td>\n","      <td>0.909200</td>\n","    </tr>\n","    <tr>\n","      <td>5500</td>\n","      <td>0.909700</td>\n","    </tr>\n","    <tr>\n","      <td>5600</td>\n","      <td>0.926400</td>\n","    </tr>\n","    <tr>\n","      <td>5700</td>\n","      <td>0.931200</td>\n","    </tr>\n","    <tr>\n","      <td>5800</td>\n","      <td>0.908000</td>\n","    </tr>\n","    <tr>\n","      <td>5900</td>\n","      <td>0.902400</td>\n","    </tr>\n","    <tr>\n","      <td>6000</td>\n","      <td>0.914300</td>\n","    </tr>\n","    <tr>\n","      <td>6100</td>\n","      <td>0.904900</td>\n","    </tr>\n","    <tr>\n","      <td>6200</td>\n","      <td>0.909500</td>\n","    </tr>\n","    <tr>\n","      <td>6300</td>\n","      <td>0.900400</td>\n","    </tr>\n","    <tr>\n","      <td>6400</td>\n","      <td>0.909000</td>\n","    </tr>\n","    <tr>\n","      <td>6500</td>\n","      <td>0.904100</td>\n","    </tr>\n","    <tr>\n","      <td>6600</td>\n","      <td>0.903700</td>\n","    </tr>\n","    <tr>\n","      <td>6700</td>\n","      <td>0.876500</td>\n","    </tr>\n","    <tr>\n","      <td>6800</td>\n","      <td>0.875300</td>\n","    </tr>\n","    <tr>\n","      <td>6900</td>\n","      <td>0.908800</td>\n","    </tr>\n","    <tr>\n","      <td>7000</td>\n","      <td>0.889900</td>\n","    </tr>\n","    <tr>\n","      <td>7100</td>\n","      <td>0.879500</td>\n","    </tr>\n","    <tr>\n","      <td>7200</td>\n","      <td>0.891700</td>\n","    </tr>\n","    <tr>\n","      <td>7300</td>\n","      <td>0.890900</td>\n","    </tr>\n","    <tr>\n","      <td>7400</td>\n","      <td>0.885700</td>\n","    </tr>\n","    <tr>\n","      <td>7500</td>\n","      <td>0.878800</td>\n","    </tr>\n","    <tr>\n","      <td>7600</td>\n","      <td>0.874400</td>\n","    </tr>\n","    <tr>\n","      <td>7700</td>\n","      <td>0.875200</td>\n","    </tr>\n","    <tr>\n","      <td>7800</td>\n","      <td>0.864100</td>\n","    </tr>\n","    <tr>\n","      <td>7900</td>\n","      <td>0.871100</td>\n","    </tr>\n","    <tr>\n","      <td>8000</td>\n","      <td>0.877500</td>\n","    </tr>\n","    <tr>\n","      <td>8100</td>\n","      <td>0.855500</td>\n","    </tr>\n","    <tr>\n","      <td>8200</td>\n","      <td>0.868800</td>\n","    </tr>\n","    <tr>\n","      <td>8300</td>\n","      <td>0.877600</td>\n","    </tr>\n","    <tr>\n","      <td>8400</td>\n","      <td>0.873900</td>\n","    </tr>\n","    <tr>\n","      <td>8500</td>\n","      <td>0.859800</td>\n","    </tr>\n","    <tr>\n","      <td>8600</td>\n","      <td>0.858200</td>\n","    </tr>\n","    <tr>\n","      <td>8700</td>\n","      <td>0.853900</td>\n","    </tr>\n","    <tr>\n","      <td>8800</td>\n","      <td>0.851400</td>\n","    </tr>\n","    <tr>\n","      <td>8900</td>\n","      <td>0.853800</td>\n","    </tr>\n","    <tr>\n","      <td>9000</td>\n","      <td>0.865600</td>\n","    </tr>\n","    <tr>\n","      <td>9100</td>\n","      <td>0.866600</td>\n","    </tr>\n","    <tr>\n","      <td>9200</td>\n","      <td>0.854300</td>\n","    </tr>\n","    <tr>\n","      <td>9300</td>\n","      <td>0.869300</td>\n","    </tr>\n","    <tr>\n","      <td>9400</td>\n","      <td>0.845500</td>\n","    </tr>\n","    <tr>\n","      <td>9500</td>\n","      <td>0.843100</td>\n","    </tr>\n","    <tr>\n","      <td>9600</td>\n","      <td>0.834400</td>\n","    </tr>\n","    <tr>\n","      <td>9700</td>\n","      <td>0.849400</td>\n","    </tr>\n","    <tr>\n","      <td>9800</td>\n","      <td>0.846300</td>\n","    </tr>\n","    <tr>\n","      <td>9900</td>\n","      <td>0.853100</td>\n","    </tr>\n","    <tr>\n","      <td>10000</td>\n","      <td>0.843900</td>\n","    </tr>\n","    <tr>\n","      <td>10100</td>\n","      <td>0.851200</td>\n","    </tr>\n","    <tr>\n","      <td>10200</td>\n","      <td>0.844700</td>\n","    </tr>\n","    <tr>\n","      <td>10300</td>\n","      <td>0.845900</td>\n","    </tr>\n","    <tr>\n","      <td>10400</td>\n","      <td>0.858900</td>\n","    </tr>\n","    <tr>\n","      <td>10500</td>\n","      <td>0.844400</td>\n","    </tr>\n","    <tr>\n","      <td>10600</td>\n","      <td>0.839800</td>\n","    </tr>\n","    <tr>\n","      <td>10700</td>\n","      <td>0.838800</td>\n","    </tr>\n","    <tr>\n","      <td>10800</td>\n","      <td>0.829300</td>\n","    </tr>\n","    <tr>\n","      <td>10900</td>\n","      <td>0.826700</td>\n","    </tr>\n","    <tr>\n","      <td>11000</td>\n","      <td>0.834400</td>\n","    </tr>\n","    <tr>\n","      <td>11100</td>\n","      <td>0.817600</td>\n","    </tr>\n","    <tr>\n","      <td>11200</td>\n","      <td>0.832400</td>\n","    </tr>\n","    <tr>\n","      <td>11300</td>\n","      <td>0.831500</td>\n","    </tr>\n","    <tr>\n","      <td>11400</td>\n","      <td>0.823500</td>\n","    </tr>\n","    <tr>\n","      <td>11500</td>\n","      <td>0.816400</td>\n","    </tr>\n","    <tr>\n","      <td>11600</td>\n","      <td>0.831100</td>\n","    </tr>\n","    <tr>\n","      <td>11700</td>\n","      <td>0.825500</td>\n","    </tr>\n","    <tr>\n","      <td>11800</td>\n","      <td>0.821700</td>\n","    </tr>\n","    <tr>\n","      <td>11900</td>\n","      <td>0.813500</td>\n","    </tr>\n","    <tr>\n","      <td>12000</td>\n","      <td>0.820400</td>\n","    </tr>\n","    <tr>\n","      <td>12100</td>\n","      <td>0.834200</td>\n","    </tr>\n","    <tr>\n","      <td>12200</td>\n","      <td>0.829200</td>\n","    </tr>\n","    <tr>\n","      <td>12300</td>\n","      <td>0.814900</td>\n","    </tr>\n","    <tr>\n","      <td>12400</td>\n","      <td>0.817500</td>\n","    </tr>\n","    <tr>\n","      <td>12500</td>\n","      <td>0.806800</td>\n","    </tr>\n","    <tr>\n","      <td>12600</td>\n","      <td>0.807200</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["TrainOutput(global_step=12652, training_loss=0.9402835745243117, metrics={'train_runtime': 23863.6685, 'train_samples_per_second': 2.651, 'train_steps_per_second': 0.53, 'total_flos': 3.649963598481408e+17, 'train_loss': 0.9402835745243117, 'epoch': 1.0})"]},"execution_count":25,"metadata":{},"output_type":"execute_result"}],"source":["# Train model\n","trainer.train()"]},{"cell_type":"markdown","metadata":{},"source":["After more than 6 and a half hours of training time, finaly the model is being saved and ready to use."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["!nvidia-smi"]},{"cell_type":"code","execution_count":26,"metadata":{"executionInfo":{"elapsed":4,"status":"aborted","timestamp":1700922904166,"user":{"displayName":"Teodor Chakarov","userId":"05481855163891350543"},"user_tz":-60},"id":"0WF83I4qy7lS"},"outputs":[{"data":{"text/plain":["('./model/new_model/tokenizer_config.json',\n"," './model/new_model/special_tokens_map.json',\n"," './model/new_model/tokenizer.json')"]},"execution_count":26,"metadata":{},"output_type":"execute_result"}],"source":["trainer.model.save_pretrained(new_model)\n","trainer.tokenizer.save_pretrained(new_model)"]},{"cell_type":"code","execution_count":27,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":182121,"status":"ok","timestamp":1700922121292,"user":{"displayName":"Teodor Chakarov","userId":"05481855163891350543"},"user_tz":-60},"id":"AVC_6avRympu","outputId":"b989b972-8c27-4317-d14f-713220ca6410"},"outputs":[{"name":"stderr","output_type":"stream","text":["/home/ubuntu/proj/venv/lib/python3.10/site-packages/transformers/generation/utils.py:1270: UserWarning: You have modified the pretrained model configuration to control generation. This is a deprecated strategy to control generation and will be removed soon, in a future version. Please use a generation configuration file (see https://huggingface.co/docs/transformers/main_classes/text_generation )\n","  warnings.warn(\n","/home/ubuntu/proj/venv/lib/python3.10/site-packages/torch/utils/checkpoint.py:31: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n","  warnings.warn(\"None of the inputs have requires_grad=True. Gradients will be None\")\n"]},{"name":"stdout","output_type":"stream","text":["[INST] What is a large language model? [/INST]  A large language model is a type of artificial intelligence (AI) model that is trained on a large corpus of text data, typically consisting of billions of words. everybody knows that language models are a type of artificial intelligence that can generate text, but what exactly is a large language model? In this article, we will explore the definition, types, and applications of large language models.\n","\n","Definition of a Large Language Model:\n","A large language model is an artificial intelligence model that is trained on a large corpus of text data. The corpus can consist of any type of text data, including books, articles, websites, and social media posts. The model is designed to learn the patterns and structures of language, allowing it to generate text that is similar to the training data.\n","\n","Types of Large Language Models:\n","There are several types of large language models, including:\n","\n","1\n"]}],"source":["# Ignore warnings\n","logging.set_verbosity(logging.CRITICAL)\n","\n","# Run text generation pipeline with our next model\n","prompt = \"What is a large language model?\"\n","pipe = pipeline(task=\"text-generation\", model=model, tokenizer=tokenizer, max_length=200)\n","result = pipe(f\"[INST] {prompt} [/INST]\")\n","print(result[0]['generated_text'])"]},{"cell_type":"code","execution_count":24,"metadata":{"executionInfo":{"elapsed":2,"status":"ok","timestamp":1700922451678,"user":{"displayName":"Teodor Chakarov","userId":"05481855163891350543"},"user_tz":-60},"id":"hCNQ5bd44Fw4"},"outputs":[],"source":["pipe = pipeline(task=\"text-generation\", model=model, tokenizer=tokenizer, max_length=200)"]},{"cell_type":"code","execution_count":49,"metadata":{"executionInfo":{"elapsed":335,"status":"ok","timestamp":1700922668971,"user":{"displayName":"Teodor Chakarov","userId":"05481855163891350543"},"user_tz":-60},"id":"T6oAkTHEymnY"},"outputs":[],"source":["def generate(text, pipeline):\n","  # Ignore warnings\n","\n","  start_time = time.time()\n","  logging.set_verbosity(logging.CRITICAL)\n","\n","  # Run text generation pipeline with our next model\n","  prompt = text\n","  result = pipeline(f\"[INST] {prompt} [/INST]\")\n","  end_time = time.time()\n","  execution_time = end_time - start_time\n","  print(\"Execution time:\",execution_time)\n","  print(result[0]['generated_text'])\n","  return result[0]['generated_text']"]},{"cell_type":"code","execution_count":31,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":168898,"status":"ok","timestamp":1700922658641,"user":{"displayName":"Teodor Chakarov","userId":"05481855163891350543"},"user_tz":-60},"id":"6j9ZIi4Aymk7","outputId":"5dd47ff7-21c2-4822-abdd-88e394a25b6f"},"outputs":[{"name":"stdout","output_type":"stream","text":["Execution time: -16.46382188796997\n","[INST] Какво да си сготвя днес? Имам картофи, месо. подправки. [/INST] Начин на приготвяне на Картофи с месо: Картофите се сваряват, обелват и нарязват на филийки. Месото се сварява, нарязва на парчета и се смесва с картофите. Подправя се на вкус. По желание може да се сложи кашкавал. 10 минути в микровълнова печка. 10 минути в микровълнова печка. 10 минути в микровълнова печка. 10 минути в микровълнова печка. 10 минути в микровълнова печка. 1\n"]}],"source":["generate(\"Какво да си сготвя днес? Имам картофи, месо. подправки.\", pipe)"]},{"cell_type":"code","execution_count":33,"metadata":{"id":"LOccYFX34Yhh"},"outputs":[{"name":"stderr","output_type":"stream","text":["/home/ubuntu/proj/venv/lib/python3.10/site-packages/torch/utils/checkpoint.py:31: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n","  warnings.warn(\"None of the inputs have requires_grad=True. Gradients will be None\")\n"]},{"name":"stdout","output_type":"stream","text":["Execution time: 17.517425775527954\n","[INST] Можеш ли да говорш на български? [/INST] Гласаният начин на говорене на български е по-добрен, защото всички звукове се опитват и се разпределят по-добре. everybody can speak Bulgarian in a fun and easy way. 1. Start with the vowels. 2. Learn the sounds of the letters. 3. Practice the sounds of the letters. 4. Learn the words. 5. Practice the words. 6. Learn the grammar. 7. Practice the grammar. 8. Learn the idioms. 9. Practice the idioms. 10. Learn the songs. 11. Practice the songs. 12. Learn the poems. 13. Practice the po\n"]}],"source":["generate(\"Можеш ли да говорш на български?\", pipe)"]},{"cell_type":"code","execution_count":34,"metadata":{"id":"iNoABumo4Ye3"},"outputs":[{"name":"stderr","output_type":"stream","text":["/home/ubuntu/proj/venv/lib/python3.10/site-packages/torch/utils/checkpoint.py:31: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n","  warnings.warn(\"None of the inputs have requires_grad=True. Gradients will be None\")\n"]},{"name":"stdout","output_type":"stream","text":["Execution time: 16.94784426689148\n","[INST] Имам ориз, мляко. какъв десерт да наравя? [/INST] Може да приготвиш Ориз с мляко: Оризът се сварява в подсолена вода. Отцежда се и се слага в купа. Млякото се загрява и се изсипва върху ориза. Разбърква се добре. По желание може да се сложи канела. По желание може да се сложи и банан. 10-15 минути се оставя да се стегне. Сервира се по желание с бита сметана. 10-15 минути преди сервиране се поръсва с канела. 10-15 минути преди сервира\n"]}],"source":["generate(\"Имам ориз, мляко. какъв десерт да наравя?\", pipe)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"accelerator":"GPU","colab":{"authorship_tag":"ABX9TyO7vhRWkLh0wv+GCWZR958N","gpuType":"T4","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.1"},"widgets":{"application/vnd.jupyter.widget-state+json":{"0dfb723963094c3d8994a3edd0716cc1":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"11f1fb24098f40bc944eebc578d47839":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2f594f7c38b8400c883556d27991d4f3":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2fcb1360c00c4754aef83ebef6ad3128":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"4e3b5c24873846bda821176a1fbacbc3":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4ed43cefc0824e869fea609b5520a6c1":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_11f1fb24098f40bc944eebc578d47839","placeholder":"​","style":"IPY_MODEL_2fcb1360c00c4754aef83ebef6ad3128","value":" 2/2 [01:05&lt;00:00, 29.60s/it]"}},"70705121ed974717aed4c0d99899d686":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_a30cd9e78033470c89174fa061f2806e","IPY_MODEL_e59a90f0aa2448adb36d7fad874c1657","IPY_MODEL_4ed43cefc0824e869fea609b5520a6c1"],"layout":"IPY_MODEL_4e3b5c24873846bda821176a1fbacbc3"}},"a30cd9e78033470c89174fa061f2806e":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_cff3274e8c6e457db45782700785ce68","placeholder":"​","style":"IPY_MODEL_0dfb723963094c3d8994a3edd0716cc1","value":"Loading checkpoint shards: 100%"}},"cff3274e8c6e457db45782700785ce68":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d6bfb3b1a0db408ebfbaa701312409b6":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"e59a90f0aa2448adb36d7fad874c1657":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_2f594f7c38b8400c883556d27991d4f3","max":2,"min":0,"orientation":"horizontal","style":"IPY_MODEL_d6bfb3b1a0db408ebfbaa701312409b6","value":2}}}}},"nbformat":4,"nbformat_minor":0}
